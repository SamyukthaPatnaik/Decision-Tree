# Decision-Tree
- Decision Tree is a Supervised learning technique that can be used for both classification and Regression problems, but mostly it is preferred for solving Classification problems. 
- Decision trees use multiple algorithms to decide to split a node into two or more sub-nodes.
- It is a tree-structured classifier, the tree can be explained by two entities, namely decision nodes and leaves, where internal nodes represent the features of a dataset, branches represent the decision rules and each leaf node represents the outcome.
- It is called a decision tree because, similar to a tree, it starts with the root node, which expands on further branches and constructs a tree-like structure.
- In order to build a tree, we use the CART algorithm, which stands for Classification and Regression Tree algorithm.

 `A decision tree can contain categorical data (YES/NO) as well as numeric data.`
1. Classification trees (Yes/No types)

What we’ve seen above is an example of classification tree, where the outcome was a variable like ‘fit’ or ‘unfit’. Here the decision variable is Categorical.

2. Regression trees (Continuous data types)

Here the decision or the outcome variable is Continuous, e.g. a number like 123. 

![Image](https://www.niser.ac.in/~smishra/teach/cs460/2020/lectures/lec3/dec_tree2.png)
